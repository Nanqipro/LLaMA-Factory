### model
model_name_or_path: ./LLM-models-datasets/Qwen2.5-3B  # 使用指定的Qwen2.5-3B模型
trust_remote_code: true

### method
stage: sft
do_train: true
finetuning_type: lora
lora_rank: 8
lora_target: all

### dataset
dataset: openr1_math_220k  # 使用在dataset_info.json中定义的数据集名称
template: qwen  # 针对Qwen模型使用qwen模板
cutoff_len: 8192  # 数学问题可能需要更长的上下文
max_samples: 93733  # 使用全部数据，共93,733个样本
overwrite_cache: true
preprocessing_num_workers: 16
dataloader_num_workers: 4

### output
output_dir: saves/qwen2.5-3b-openr1-math-220k/lora/sft  # 更明确的输出目录名称
logging_dir: logs/qwen2.5-3b-openr1-math-220k/lora/sft  # 日志输出目录
logging_steps: 10
save_steps: 1000
plot_loss: true
overwrite_output_dir: true
save_only_model: false
report_to: tensorboard  # 使用tensorboard记录训练过程
logging_first_step: true  # 记录第一步
logging_nan_inf_filter: true  # 过滤NaN和Inf值
log_level: info  # 日志级别

### train
per_device_train_batch_size: 1  # 数学推理任务使用较小的batch size
gradient_accumulation_steps: 8  # 增加梯度累积步数以保持有效batch size
learning_rate: 3.0e-5  # 数学推理任务使用较小的学习率
num_train_epochs: 2.0  # 数学推理任务通常需要较少epochs
lr_scheduler_type: cosine
warmup_ratio: 0.05  # 较小的warmup比例
bf16: true  # Qwen2.5支持bf16，提升训练效率
ddp_timeout: 180000000
resume_from_checkpoint: null

### eval
val_size: 0.1  # 使用10%数据作为验证集
per_device_eval_batch_size: 1
eval_strategy: steps
eval_steps: 1000
eval_on_start: false

### 针对数学推理任务和Qwen模型的特殊设置
use_fast_tokenizer: false  # Qwen模型推荐设置
max_grad_norm: 1.0  # 梯度裁剪，防止梯度爆炸
weight_decay: 0.01  # 权重衰减
adam_beta1: 0.9
adam_beta2: 0.95
adam_epsilon: 1e-8
dataloader_pin_memory: true  # 加速数据加载
dataloader_persistent_workers: true  # 保持数据加载worker 