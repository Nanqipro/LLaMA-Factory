# Bespoke-Stratos-17k æ•°æ®é›† LoRA å¾®è°ƒæŒ‡å—

## æ¦‚è¿°

æœ¬æŒ‡å—ä»‹ç»å¦‚ä½•ä½¿ç”¨ LLaMA-Factory å¯¹ Bespoke-Stratos-17k æ•°æ®é›†è¿›è¡Œ LoRA å¾®è°ƒã€‚è¯¥æ•°æ®é›†åŒ…å« 16,710 ä¸ªé«˜è´¨é‡çš„å¯¹è¯æ ·æœ¬ï¼Œé‡‡ç”¨ sharegpt æ ¼å¼ï¼Œéå¸¸é€‚åˆç”¨äºæŒ‡ä»¤å¾®è°ƒã€‚

## æ•°æ®é›†ä¿¡æ¯

- **æ•°æ®é›†åç§°**: Bespoke-Stratos-17k
- **æ ·æœ¬æ•°é‡**: 16,710
- **æ ¼å¼**: sharegptï¼ˆåŒ…å« system å’Œ conversations å­—æ®µï¼‰
- **æ–‡ä»¶ç±»å‹**: Arrow æ ¼å¼
- **å…¼å®¹æ€§**: å®Œå…¨å…¼å®¹ LLaMA-Factory

## é¢„å¤‡æ¡ä»¶

### 1. ç¯å¢ƒè¦æ±‚
- Python 3.8+
- PyTorch 1.13+
- CUDA 11.8+ (æ¨è)
- æ˜¾å­˜è¦æ±‚: è‡³å°‘ 12GBï¼ˆ8B æ¨¡å‹ï¼‰

### 2. å®‰è£…ä¾èµ–
```bash
pip install -r requirements.txt
```

### 3. æ•°æ®é›†æ£€æŸ¥
ç¡®ä¿æ•°æ®é›†æ–‡ä»¶å­˜åœ¨ï¼š
```bash
ls -la LLM-models-datasets/Bespoke-Stratos-17k/bespokelabs___bespoke-stratos-17k/default-45716a10dbb21a2b/0.0.0/master/bespoke-stratos-17k-train.arrow
```

## å¿«é€Ÿå¼€å§‹

### 1. ä¸€é”®å¯åŠ¨è®­ç»ƒ
```bash
bash train_bespoke_stratos.sh
```

### 2. æ‰‹åŠ¨å¯åŠ¨è®­ç»ƒ
```bash
python -m llamafactory.train examples/train_lora/bespoke_stratos_lora_sft.yaml
```

### 3. æµ‹è¯•å¾®è°ƒåçš„æ¨¡å‹
```bash
# æµ‹è¯•å¾®è°ƒåçš„æ¨¡å‹
python test_bespoke_model.py

# æµ‹è¯•åŸå§‹æ¨¡å‹ï¼ˆå¯¹æ¯”ï¼‰
python test_bespoke_model.py --no_lora
```

## é…ç½®è¯´æ˜

### æ•°æ®é›†é…ç½® (data/dataset_info.json)
```json
"bespoke_stratos_17k": {
  "file_name": "../LLM-models-datasets/Bespoke-Stratos-17k/bespokelabs___bespoke-stratos-17k/default-45716a10dbb21a2b/0.0.0/master/bespoke-stratos-17k-train.arrow",
  "formatting": "sharegpt",
  "columns": {
    "messages": "conversations",
    "system": "system"
  },
  "tags": {
    "role_tag": "from",
    "content_tag": "value",
    "user_tag": "human",
    "assistant_tag": "gpt"
  }
}
```

### è®­ç»ƒé…ç½®å…³é”®å‚æ•°

| å‚æ•° | å€¼ | è¯´æ˜ |
|------|----|----|
| model_name_or_path | meta-llama/Meta-Llama-3-8B-Instruct | åŸºç¡€æ¨¡å‹ |
| lora_rank | 8 | LoRA ç§©ï¼Œæ§åˆ¶é€‚é…å™¨å¤§å° |
| lora_target | all | åº”ç”¨ LoRA çš„å±‚ |
| cutoff_len | 4096 | æœ€å¤§åºåˆ—é•¿åº¦ |
| learning_rate | 5.0e-5 | å­¦ä¹ ç‡ |
| num_train_epochs | 3.0 | è®­ç»ƒè½®æ•° |
| per_device_train_batch_size | 2 | æ‰¹å¤§å° |

## é«˜çº§é…ç½®

### 1. æ¨¡å‹é€‰æ‹©
æ”¯æŒå¤šç§æ¨¡å‹ï¼Œä¿®æ”¹ `model_name_or_path` å³å¯ï¼š
- `meta-llama/Meta-Llama-3-8B-Instruct`
- `Qwen/Qwen2.5-7B-Instruct`
- `mistralai/Mistral-7B-Instruct-v0.3`

### 2. æ˜¾å­˜ä¼˜åŒ–
#### å°æ˜¾å­˜é…ç½®ï¼ˆ<12GBï¼‰
```yaml
per_device_train_batch_size: 1
gradient_accumulation_steps: 8
fp16: true  # ä½¿ç”¨ fp16 è€Œé bf16
```

#### é‡åŒ–è®­ç»ƒ
```yaml
quantization_bit: 4
quantization_type: nf4
```

### 3. æ•°æ®é‡‡æ ·
#### å¿«é€Ÿæµ‹è¯•ï¼ˆ1000æ ·æœ¬ï¼‰
```yaml
max_samples: 1000
num_train_epochs: 1.0
```

#### å®Œæ•´è®­ç»ƒï¼ˆå…¨éƒ¨æ•°æ®ï¼‰
```yaml
max_samples: 16710
num_train_epochs: 3.0
```

## ç›‘æ§ä¸è¯„ä¼°

### 1. è®­ç»ƒæ—¥å¿—ç³»ç»Ÿ
æˆ‘ä»¬å·²ç»é…ç½®äº†å®Œæ•´çš„æ—¥å¿—ç³»ç»Ÿï¼Œæ‰€æœ‰è®­ç»ƒè¿‡ç¨‹éƒ½ä¼šè®°å½•åˆ°æŒ‡å®šè·¯å¾„ï¼š

#### ğŸ“‹ æ—¥å¿—æ–‡ä»¶ç»“æ„
```
logs/qwen2.5-3b-bespoke-stratos/lora/sft/
â”œâ”€â”€ training_YYYYMMDD_HHMMSS.log  # è¯¦ç»†è®­ç»ƒæ—¥å¿—
â”œâ”€â”€ error_YYYYMMDD_HHMMSS.log     # é”™è¯¯æ—¥å¿—
â””â”€â”€ tensorboardäº‹ä»¶æ–‡ä»¶            # TensorBoardå¯è§†åŒ–æ•°æ®
```

#### ğŸ” å®æ—¶ç›‘æ§è®­ç»ƒ
```bash
# å¯åŠ¨è®­ç»ƒç›‘æ§å·¥å…·
bash monitor_training.sh

# é€‰é¡¹åŒ…æ‹¬ï¼š
# 1) å®æ—¶æ˜¾ç¤ºæœ€æ–°æ—¥å¿—
# 2) æŸ¥çœ‹å®Œæ•´æ—¥å¿—å†…å®¹  
# 3) æŸ¥çœ‹è®­ç»ƒè¿›åº¦å’ŒæŸå¤±
# 4) æŸ¥çœ‹GPUä½¿ç”¨æƒ…å†µ
# 5) å¯åŠ¨TensorBoard
# 6) æŸ¥çœ‹é”™è¯¯æ—¥å¿—
# 7) æ˜¾ç¤ºè®­ç»ƒç»Ÿè®¡ä¿¡æ¯
```

#### ğŸ“Š TensorBoardå¯è§†åŒ–
```bash
# å¯åŠ¨TensorBoard
bash start_tensorboard.sh

# è®¿é—®åœ°å€: http://localhost:6006
# è¿œç¨‹æœåŠ¡å™¨è¯·ä½¿ç”¨ç«¯å£è½¬å‘:
# ssh -L 6006:localhost:6006 username@server_ip
```

#### ğŸ“ˆ æ—¥å¿—åˆ†æå’ŒæŠ¥å‘Š
```bash
# åˆ†æè®­ç»ƒæ—¥å¿—ï¼Œç”Ÿæˆç»Ÿè®¡æŠ¥å‘Šå’Œå¯è§†åŒ–å›¾è¡¨
python analyze_training_logs.py

# æŒ‡å®šç‰¹å®šæ—¥å¿—æ–‡ä»¶
python analyze_training_logs.py --log-file logs/xxx/training_xxx.log

# è‡ªå®šä¹‰è¾“å‡ºç›®å½•
python analyze_training_logs.py --output-dir my_analysis
```

### 2. è®­ç»ƒæ—¥å¿—åŠŸèƒ½

#### âœ… è‡ªåŠ¨è®°å½•çš„ä¿¡æ¯
- **ç³»ç»Ÿä¿¡æ¯**: æ“ä½œç³»ç»Ÿã€Pythonç‰ˆæœ¬ã€CUDAè®¾å¤‡
- **GPUçŠ¶æ€**: æ˜¾å­˜ä½¿ç”¨æƒ…å†µã€GPUå‹å·
- **é…ç½®ä¿¡æ¯**: å®Œæ•´çš„è®­ç»ƒé…ç½®æ–‡ä»¶å†…å®¹
- **è®­ç»ƒè¿›åº¦**: æ­¥æ•°ã€è½®æ¬¡ã€æŸå¤±å€¼ã€å­¦ä¹ ç‡
- **æ—¶é—´æˆ³**: è®­ç»ƒå¼€å§‹/ç»“æŸæ—¶é—´
- **é”™è¯¯ä¿¡æ¯**: è¯¦ç»†çš„é”™è¯¯å †æ ˆä¿¡æ¯

#### ğŸ“‹ æ—¥å¿—å†…å®¹ç¤ºä¾‹
```
==========================================
è®­ç»ƒå¼€å§‹æ—¶é—´: 2024-12-09 20:49:03
==========================================
ç³»ç»Ÿä¿¡æ¯:
- æ“ä½œç³»ç»Ÿ: Linux DGX-Station 6.8.0-60-generic
- Pythonç‰ˆæœ¬: Python 3.11.0
- CUDAè®¾å¤‡: 0,1,2,3
- GPUä¿¡æ¯:
NVIDIA RTX 4090, 24564, 1024, 23540
==========================================
é…ç½®æ–‡ä»¶å†…å®¹:
[é…ç½®æ–‡ä»¶å®Œæ•´å†…å®¹]
==========================================
å¼€å§‹è®­ç»ƒ...
è®­ç»ƒå‘½ä»¤: llamafactory-cli train examples/train_lora/bespoke_stratos_lora_sft.yaml
----------------------------------------
[è®­ç»ƒè¿‡ç¨‹è¯¦ç»†æ—¥å¿—]
----------------------------------------
è®­ç»ƒç»“æŸæ—¶é—´: 2024-12-09 23:45:12
è®­ç»ƒé€€å‡ºä»£ç : 0
âœ… è®­ç»ƒæˆåŠŸå®Œæˆï¼
ğŸ“ æ¨¡å‹ä¿å­˜åœ¨: saves/qwen2.5-3b-bespoke-stratos/lora/sft/
ğŸ“Š è®­ç»ƒæ—¥å¿—ä¿å­˜åœ¨: logs/xxx/training_xxx.log
ğŸ“ˆ TensorBoardæ—¥å¿—ä¿å­˜åœ¨: logs/qwen2.5-3b-bespoke-stratos/lora/sft/
```

### 3. éªŒè¯è¯„ä¼°
å¯ç”¨éªŒè¯é›†è¯„ä¼°ï¼š
```yaml
val_size: 0.1
eval_strategy: steps
eval_steps: 500
```

### 4. å¤–éƒ¨ç›‘æ§å·¥å…·
æ”¯æŒå¤šç§ç›‘æ§å·¥å…·ï¼š
```yaml
report_to: tensorboard  # é€‰é¡¹: tensorboard, wandb, mlflow
logging_dir: logs/qwen2.5-3b-bespoke-stratos/lora/sft
```

## æ¨ç†ä½¿ç”¨

### 1. API æœåŠ¡
```bash
python -m llamafactory.api \
    --model_name_or_path meta-llama/Meta-Llama-3-8B-Instruct \
    --adapter_name_or_path saves/bespoke-stratos/lora/sft \
    --template llama3
```

### 2. å‘½ä»¤è¡ŒèŠå¤©
```bash
python -m llamafactory.chat \
    --model_name_or_path meta-llama/Meta-Llama-3-8B-Instruct \
    --adapter_name_or_path saves/bespoke-stratos/lora/sft \
    --template llama3
```

### 3. Web UI
```bash
python -m llamafactory.webui
```

## æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **æ•°æ®é›†è·¯å¾„é”™è¯¯**
   ```
   ç¡®ä¿è·¯å¾„æ­£ç¡®: ../LLM-models-datasets/Bespoke-Stratos-17k/...
   ```

2. **æ˜¾å­˜ä¸è¶³**
   ```yaml
   # å‡å°æ‰¹å¤§å°å’Œåºåˆ—é•¿åº¦
   per_device_train_batch_size: 1
   cutoff_len: 2048
   ```

3. **è®­ç»ƒä¸æ”¶æ•›**
   ```yaml
   # è°ƒæ•´å­¦ä¹ ç‡
   learning_rate: 2.0e-5  # æ›´å°çš„å­¦ä¹ ç‡
   ```

4. **æ¨¡æ¿ä¸åŒ¹é…**
   ```yaml
   # æ ¹æ®æ¨¡å‹é€‰æ‹©æ­£ç¡®æ¨¡æ¿
   template: llama3  # æˆ– qwen, mistral ç­‰
   ```

### æ—¥å¿—åˆ†æ
æŸ¥çœ‹è®­ç»ƒæ—¥å¿—ï¼š
```bash
tail -f saves/bespoke-stratos/lora/sft/trainer_log.jsonl
```

## æ€§èƒ½ä¼˜åŒ–å»ºè®®

### 1. ç¡¬ä»¶é…ç½®
- æ¨è: RTX 4090 / A100 (24GB+)
- æœ€ä½: RTX 3090 / V100 (12GB+)

### 2. è®­ç»ƒæŠ€å·§
- ä½¿ç”¨ DeepSpeed ZeRO-2 æå‡æ•ˆç‡
- å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹èŠ‚çœæ˜¾å­˜
- åˆç†è®¾ç½®æ•°æ®å¹¶è¡Œ

### 3. è¶…å‚æ•°è°ƒä¼˜
- LoRA rank: 8-32 (å¹³è¡¡æ•ˆæœä¸æ•ˆç‡)
- å­¦ä¹ ç‡: 1e-5 åˆ° 1e-4
- Warmup ratio: 0.05-0.1

## ç»“è®º

Bespoke-Stratos-17k æ•°æ®é›†å®Œå…¨å…¼å®¹ LLaMA-Factoryï¼Œæ— éœ€ä¿®æ”¹æ•°æ®æ ¼å¼ã€‚é€šè¿‡åˆç†çš„é…ç½®ï¼Œå¯ä»¥é«˜æ•ˆåœ°è¿›è¡Œ LoRA å¾®è°ƒï¼Œæå‡æ¨¡å‹çš„å¯¹è¯èƒ½åŠ›å’ŒæŒ‡ä»¤éµå¾ªæ€§èƒ½ã€‚

å»ºè®®ä»å°æ ·æœ¬å¼€å§‹æµ‹è¯•ï¼Œç¡®è®¤é…ç½®æ— è¯¯åå†è¿›è¡Œå®Œæ•´è®­ç»ƒã€‚ 